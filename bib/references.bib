[3:10 pm] Akil Abdul Samad




 

@article{10.1007/978-3-319-44781-0_11,

author={David, Omid E.and Netanyahu, Nathan S.and Wolf, Lior},

editor={Villa, Alessandro E.P.and Masulli,Paolo and Pons Rivero, Antonio Javier},

title={DeepChess: End-to-End Deep Neural Network for Automatic Learning in Chess},

booktitle={Artificial Neural Networks and Machine Learning -- ICANN 2016},

year={2016},

publisher={Springer International Publishing},

journal={Springer},

pages={88--96},

abstract={We present an end-to-end learning method for chess, relying on deep neural networks. Without any a priori knowledge, in particular without any knowledge regarding the rules of chess, a deep neural network is trained using a combination of unsupervised pretraining and supervised training. The unsupervised training extracts high level features from a given position, and the supervised training learns to compare two chess positions and select the more favorable one. The training relies entirely on datasets of several million chess games, and no further domain specific knowledge is incorporated.},

isbn={978-3-319-44781-0},

url = {https://www.cs.tau.ac.il/~wolf/papers/deepchess.pdf},

doi = {10.1007/978-3-319-44781-0_11},

number = {02},

keywords = {type:system, visual_analytics, sparklines, information_retrieval, clustering, literature_browser}

}

 



@ARTICLE{6626616,

  author={David, Omid E. and van den Herik, H. Jaap and Koppel, Moshe and Netanyahu, Nathan S.},

  journal={IEEE Transactions on Evolutionary Computation}, 

  title={Genetic Algorithms for Evolving Computer Chess Programs}, 

  year={2014},

  volume={18},

  number={5},

  pages={779-789},

  abstract={This paper demonstrates the use of genetic algorithms for evolving: 1) a grandmaster-level evaluation function, and 2) a search mechanism for a chess program, the parameter values of which are initialized randomly. The evaluation function of the program is evolved by learning from databases of (human) grandmaster games. At first, the organisms are evolved to mimic the behavior of human grandmasters, and then these organisms are further improved upon by means of coevolution. The search mechanism is evolved by learning from tactical test suites. Our results show that the evolved program outperforms a two-time world computer chess champion and is at par with the other leading computer chess programs.},

  keywords={conventional, evolutionary learning},

  doi={10.1109/TEVC.2013.2285111},

  ISSN={1941-0026},

  month={Oct}

  }

 

 



@ARTICLE{1360168,

  author={Fogel, D.B. and Hays, T.J. and Hahn, S.L. and Quon, J.},

  journal={Proceedings of the IEEE}, 

  title={A self-learning evolutionary chess program}, 

  year={2004},

  volume={92},

  number={12},

  pages={1947-1954},

  abstract={A central challenge of artificial intelligence is to create machines that can learn from their own experience and perform at the level of human experts. Using an evolutionary algorithm, a computer program has learned to play chess by playing games against itself. The program learned to evaluate chessboard configurations by using the positions of pieces, material and positional values, and neural networks to assess specific sections of the chessboard. During evolution, the program improved its play by almost 400 rating points. Testing under simulated tournament conditions against Pocket Fritz 2.0 indicated that the evolved program performs above the master level.},

  keywords={visual_analytics, sparklines, information_retrieval, clustering,chess, spark },

  doi={10.1109/JPROC.2004.837633},

  ISSN={1558-2256},

  month={Dec},}

 

 

@article{Chen2016ComputerVB,

  title={Computer vision based chess playing capabilities for the Baxter humanoid robot},

  author={Andrew Tzer-Yeu Chen and Kevin I-Kai Wang},

  journal={2016 2nd International Conference on Control, Automation and Robotics (ICCAR)},

  year={2016},

  pages={11-14},

  abstract={This paper presents a project that allows the Baxter humanoid robot to play chess against human players autonomously. The complete solution uses three main subsystems: computer vision based on a single camera embedded in Baxter's arm to perceive the game state, an open-source chess engine to compute the next move, and a mechatronics subsystem with a 7-DOF arm to manipulate the pieces. Baxter can play chess successfully in unconstrained environments by dynamically responding to changes in the environment. This implementation demonstrates Baxter's capabilities of vision-based adaptive control and small-scale manipulation, which can be applicable to numerous applications, while also contributing to the computer vision chess analysis literature. },

  keywords={vIswn; uncontrolled environments; mechatronics; human-robot interaction; chess robot},


 

}

 



@article{Panchal2021ChessMP,

  title={Chess Moves Prediction using Deep Learning Neural Networks},

  author={Hitanshu Panchal and Siddhant Mishra and Varsha Shrivastava},

  journal={2021 International Conference on Advances in Computing and Communications (ICACC)},

  year={2021},

  pages={1-6},

    abstract={Chess is a game that is popular for high intelligence and strategic thinking. There has been a lot of research on chess for predicting chess moves, applying chess game theory, and automating chess games. The art of playing chess using computer vision can be implemented using various learning algorithms. A class of Deep Learning has the ability to solve problems of predicting chess moves although facing the necessity of huge datasets. The traditional chess algorithm Minimax with the Convolutional Neural Network can perceive and learn the patterns and rules in chess i.e., identification of some small and native tactics of the game, and should be trained on this method with appropriate functions for smarter universal play. CNN when trained with appropriate architecture and validation data can learn to function based on the reasoning in complex logical tasks. Training on 15,00,000 board states in the dataset which is a board state represented as 8x8x14 dimensions. Each board state is given as an input to the input layer of the Convolutional Neural Network. The CNN model tested and validated against the stockfish chess engine achieved the best accuracy of 39.16% for board evaluation. However, this doesn’t reflect the actual accuracy of the model since the evaluation by the model is relative for two different board states. CNN learning the game of chess and based on the result of chess is essentially pre-computation on a given situation.},

  keywords={vIswn; uncontrolled environments; mechatronics; human-robot interaction; chess robot},


}

 



@article{David2010OptimizingSS,

  title={Optimizing Selective Search in Chess},

  author={Omid David and Moshe Koppel and Nathan S. Netanyahu},

  journal={ArXiv},

  year={2010},

  volume={abs/1009.0550},

   abstract={In this paper we introduce a novel method for automatically tuning the search parameters of a chess program using genetic algorithms. Our results show that a large set of parame- ter values can be learned automatically, such that the resulting performance is comparable with that of manually tuned parameters of top tournament-playing chess programs.},

  keywords={ai, optimizing, search, tree search, chess },


}

 



@article{Madake2023CHESSAM,

  title={CHESS AI: Machine learning and Minimax based Chess Engine},

  author={Jyoti Madake and Chinmay Deotale and Geetai Charde and Shripad Bhatlawande},

  journal={2023 International Conference for Advancement in Technology (ICONAT)},

  year={2023},

  pages={1-6},

   abstract={ Designing Chess Engine has been a main focus of research for a long time. The paper employs a novel combination approach of Machine learning based estimator with artificial intelligence (AI) to build chess AI. The Minimax Algorithm is a decision theory-based technique implemented for reducing the load on the chess engine's hardware. Also, Alpha-Beta Pruning algorithm is implemented to eliminate any nodes in the search tree that aren't essential and hence makes the AI efficient. Trained estimators achieved a high accuracy of 96.77% for calculating the probability of ‘good move’. A variable depth of search tree based on the number of legal moves has also been employed for the minimax algorithm.},

  keywords={ Chess engine, Machine learning, Minimax, Alpha- Beta pruning.},

}

 

 

 

@inproceedings{NIPS1994_d7322ed7,

author = {Thrun, Sebastian},

booktitle = {Advances in Neural Information Processing Systems},

editor = {G. Tesauro and D. Touretzky and T. Leen},

pages = {},

publisher = {MIT Press},

title = {Learning to Play the Game of Chess},

url = {https://proceedings.neurips.cc/paper_files/paper/1994/file/d7322ed717dedf1eb4e6e52a37ea7bcd-Paper.pdf},

volume = {7},

year = {1994},

abstract={ This paper presents NeuroChess, a program which learns to play chess from the final outcome of games. NeuroChess learns chess board evaluation functions, represented by artificial neural networks. It integrates inductive neural network learning, temporal differencing, and a variant of explanation-based learning. Performance results illustrate some of the strengths and weaknesses of this approach.

},

  keywords={ Chess engine, Machine learning, TD},

}

 



@article{SaiKrishnaG2018DeepPE,

  title={Deep Pepper: Expert Iteration based Chess agent in the Reinforcement Learning Setting},

  author={V. SaiKrishnaG. and Kyle Goyette and Ahmad Chamseddine and Breandan Considine},

  journal={ArXiv},

  year={2018},

  volume={abs/1806.00683},

  abstract={ An almost-perfect chess playing agent has been a long standing challenge in the

field of Artificial Intelligence. Some of the recent advances demonstrate we are

approaching that goal. In this project, we provide methods for faster training of

self-play style algorithms, mathematical details of the algorithm used, various

potential future directions, and discuss most of the relevant work in the area of

computer chess. Deep Pepper uses embedded knowledge to accelerate the training

of the chess engine over a "tabula rasa" system such as Alpha Zero. We also release

our code to promote further research

},

  keywords={ deep, chess, reingotment, learning, ai},

}

 

@article{lai2015giraffe,

  title={Giraffe: Using deep reinforcement learning to play chess},

  author={Lai, Matthew},

  journal={arXiv preprint arXiv:1509.01549},

  year={2015},

  abstract={ This report presents Giraffe, a chess engine that uses self-play to discover all its domain-specific knowledge, with minimal hand-crafted knowledge given by the pro- grammer. Unlike previous attempts using machine learning only to perform parameter- tuning on hand-crafted evaluation functions, Giraffe’s learning system also performs automatic feature extraction and pattern recognition. The trained evaluation function performs comparably to the evaluation functions of state-of-the-art chess engines - all of which containing thousands of lines of carefully hand-crafted pattern recognizers, tuned over many years by both computer chess experts and human chess masters. Giraffe is the most successful attempt thus far at using end-to-end machine learning to play chess.

We also investigated the possibility of using probability thresholds instead of depth to shape search trees. Depth-based searches form the backbone of virtually all chess engines in existence today, and is an algorithm that has become well-established over the past half century. Preliminary comparisons between a basic implementation of probability-based search and a basic implementation of depth-based search showed that our new probability-based approach performs moderately better than the established approach. There are also evidences suggesting that many successful ad-hoc add-ons to depth-based searches are generalized by switching to a probability-based search. We believe the probability-based search to be a more fundamentally correct way to perform minimax.

Finally, we designed another machine learning system to shape search trees within the probability-based search framework. Given any position, this system estimates the probability of each of the moves being the best move without looking ahead. The system is highly effective - the actual best move is within the top 3 ranked moves 70% of the time, out of an average of approximately 35 legal moves from each position. This also resulted in a significant increase in playing strength.

With the move evaluator guiding a probability-based search using the learned eval- uator, Giraffe plays at approximately the level of an FIDE International Master (top 2.2% of tournament chess players with an official rating)12.

},

  keywords={ similarity, neaural network, TD-leaf, deep learning},

}

 

 
